/usr/bin/python3.5 "/home/fractal/PycharmProjects/hologram_SVM/check past_sixteen.py"
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.683
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.43GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
WARNING:tensorflow:From /home/fractal/PycharmProjects/hologram_SVM/check past_sixteen.py:205: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
train # 0
shape(?, 19)
shape(?, 19)
Tensor("Mean_3:0", shape=(), dtype=float32)
WARNING:tensorflow:From /home/fractal/PycharmProjects/hologram_SVM/check past_sixteen.py:444: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
step 0, training accuracy 0.0657895
Validation accuracy: 0.046579
Variance:0.000396191
loss:3.26486

/usr/lib/python3/dist-packages/matplotlib/backend_bases.py:2437: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented
  warnings.warn(str, mplDeprecation)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 7286 get requests, put_count=7247 evicted_count=1000 eviction_rate=0.137988 and unsatisfied allocation rate=0.156327
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
step 100, training accuracy 0.842105
Validation accuracy: 0.718158
Variance:0.00219591
loss:0.633289

step 200, training accuracy 0.868421
Validation accuracy: 0.799211
Variance:0.00196544
loss:0.492262

step 300, training accuracy 0.960526
Validation accuracy: 0.815263
Variance:0.00144709
loss:0.264656

step 400, training accuracy 0.93421
Validation accuracy: 0.818947
Variance:0.00174903
loss:0.262951

step 500, training accuracy 0.93421
Validation accuracy: 0.834474
Variance:0.0010394
loss:0.182462

step 600, training accuracy 0.960526
Validation accuracy: 0.841842
Variance:0.00136766
loss:0.128442

step 700, training accuracy 0.947368
Validation accuracy: 0.810263
Variance:0.00121946
loss:0.23537

step 800, training accuracy 0.960526
Validation accuracy: 0.803158
Variance:0.00154404
loss:0.0742452

step 900, training accuracy 0.947368
Validation accuracy: 0.823684
Variance:0.000831025
loss:0.14999

step 1000, training accuracy 0.960526
Validation accuracy: 0.835
Variance:0.00117181
loss:0.136716

step 1100, training accuracy 0.986842
Validation accuracy: 0.83
Variance:0.0011831
loss:0.0602485

step 1200, training accuracy 1
Validation accuracy: 0.862105
Variance:0.00135208
loss:0.0403069

step 1300, training accuracy 0.973684
Validation accuracy: 0.876053
Variance:0.00121253
loss:0.0848173

step 1400, training accuracy 0.973684
Validation accuracy: 0.802368
Variance:0.00167929
loss:0.193635

step 1500, training accuracy 0.973684
Validation accuracy: 0.848158
Variance:0.00172583
loss:0.113581

step 1600, training accuracy 1
Validation accuracy: 0.836579
Variance:0.00177348
loss:0.0374511

step 1700, training accuracy 0.947368
Validation accuracy: 0.829211
Variance:0.00162389
loss:0.277726

step 1800, training accuracy 0.986842
Validation accuracy: 0.829211
Variance:0.00129841
loss:0.0656267

step 1900, training accuracy 0.960526
Validation accuracy: 0.822895
Variance:0.00087403
loss:0.070421

step 2000, training accuracy 1
Validation accuracy: 0.839211
Variance:0.00136627
loss:0.0339181

step 2100, training accuracy 0.973684
Validation accuracy: 0.864211
Variance:0.000917175
loss:0.0349909

step 2200, training accuracy 0.986842
Validation accuracy: 0.819737
Variance:0.0014768
loss:0.0602495

step 2300, training accuracy 0.973684
Validation accuracy: 0.823684
Variance:0.00126731
loss:0.201202

step 2400, training accuracy 0.973684
Validation accuracy: 0.85
Variance:0.00130886
loss:0.0691905

step 2500, training accuracy 0.986842
Validation accuracy: 0.829211
Variance:0.00127763
loss:0.149482

step 2600, training accuracy 0.986842
Validation accuracy: 0.831053
Variance:0.00142909
loss:0.0306728

step 2700, training accuracy 0.973684
Validation accuracy: 0.825
Variance:0.00137985
loss:0.0805662

step 2800, training accuracy 0.973684
Validation accuracy: 0.850789
Variance:0.00120921
loss:0.0334675

step 2900, training accuracy 0.973684
Validation accuracy: 0.853947
Variance:0.00168456
loss:0.226664

step 3000, training accuracy 1
Validation accuracy: 0.843947
Variance:0.000768767
loss:0.00504566

0
[ 0.8245614   0.          0.05263158  0.          0.12280702  0.          0.
  0.          0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.        ]
1
[ 0.          0.97530864  0.          0.00740741  0.          0.          0.
  0.00987654  0.          0.          0.          0.00246914  0.          0.
  0.          0.00493827  0.          0.          0.        ]
2
[ 0.04444444  0.          0.88888889  0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.06666667  0.        ]
3
[ 0.01282051  0.          0.03846154  0.91025641  0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.01282051  0.          0.          0.          0.02564103  0.        ]
4
[ 0.          0.          0.          0.          0.98780488  0.
  0.01219512  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.        ]
5
[ 0.          0.          0.          0.          0.          0.94350282
  0.00564972  0.02259887  0.          0.          0.          0.
  0.02824859  0.          0.          0.          0.          0.          0.        ]
6
[ 0.00460405  0.          0.          0.          0.01012891  0.
  0.98526703  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.        ]
7
[ 0.          0.01269841  0.          0.          0.          0.0031746
  0.00952381  0.85079365  0.          0.          0.          0.
  0.11746032  0.          0.          0.          0.00634921  0.          0.        ]
8
[ 0.          0.          0.          0.          0.          0.          0.
  0.          0.96923077  0.          0.          0.          0.01538462
  0.          0.01025641  0.00512821  0.          0.          0.        ]
9
[ 0.          0.          0.          0.          0.          0.
  0.13531353  0.          0.          0.86468647  0.          0.          0.
  0.          0.          0.          0.          0.          0.        ]
10
[ 0.          0.00813008  0.          0.          0.          0.          0.
  0.          0.          0.          0.94308943  0.04065041  0.00813008
  0.          0.          0.          0.          0.          0.        ]
11
[ 0.          0.01587302  0.          0.03174603  0.          0.          0.
  0.          0.          0.          0.          0.9047619   0.04761905
  0.          0.          0.          0.          0.          0.        ]
12
[ 0.          0.00277778  0.00277778  0.          0.00277778  0.02222222
  0.          0.          0.          0.          0.          0.
  0.66388889  0.          0.00833333  0.03888889  0.25833333  0.          0.        ]
13
[ 0.          0.38888889  0.          0.          0.          0.          0.
  0.05555556  0.          0.          0.          0.11111111  0.
  0.44444444  0.          0.          0.          0.          0.        ]
14
[ 0.          0.          0.          0.          0.          0.          0.
  0.          0.11111111  0.          0.          0.          0.          0.
  0.88888889  0.          0.          0.          0.        ]
15
[ 0.          0.02777778  0.          0.          0.          0.          0.
  0.          0.08333333  0.          0.          0.          0.05555556
  0.          0.          0.77777778  0.05555556  0.          0.        ]
16
[ 0.          0.          0.          0.          0.          0.01814059
  0.03854875  0.          0.          0.          0.          0.
  0.07029478  0.          0.          0.02040816  0.85260771  0.          0.        ]
17
[ 0.04166667  0.125       0.125       0.25        0.          0.          0.
  0.04166667  0.          0.          0.          0.          0.04166667
  0.          0.          0.          0.          0.375       0.        ]
18
[ 0.          0.          0.          0.          0.0273224   0.
  0.03278689  0.01639344  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.92349727]
Model saved in file: /home/fractal/workspace/02_hoi/4Deep/classes19/save_dir

Process finished with exit code 0
