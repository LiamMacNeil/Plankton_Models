/usr/bin/python3.5 "/home/fractal/PycharmProjects/hologram_SVM/check past_sixteen.py"
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.683
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.47GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
WARNING:tensorflow:From /home/fractal/PycharmProjects/hologram_SVM/check past_sixteen.py:205: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
train # 0
WARNING:tensorflow:From /home/fractal/PycharmProjects/hologram_SVM/check past_sixteen.py:444: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
shape(?, 19)
shape(?, 19)
Tensor("Mean_3:0", shape=(), dtype=float32)
step 0, training accuracy 0.0263158
Validation accuracy: 0.0244737
Variance:0.000166274
loss:3.1992

/usr/lib/python3/dist-packages/matplotlib/backend_bases.py:2437: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented
  warnings.warn(str, mplDeprecation)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 7286 get requests, put_count=7247 evicted_count=1000 eviction_rate=0.137988 and unsatisfied allocation rate=0.156327
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
step 100, training accuracy 0.868421
Validation accuracy: 0.705263
Variance:0.00137119
loss:0.761366

step 200, training accuracy 0.868421
Validation accuracy: 0.773947
Variance:0.0025394
loss:0.504652

step 300, training accuracy 0.947368
Validation accuracy: 0.772632
Variance:0.00118449
loss:0.242911

step 400, training accuracy 0.93421
Validation accuracy: 0.796579
Variance:0.00124107
loss:0.266245

step 500, training accuracy 0.947368
Validation accuracy: 0.810789
Variance:0.00157819
loss:0.238818

step 600, training accuracy 0.986842
Validation accuracy: 0.813158
Variance:0.0018421
loss:0.0913325

step 700, training accuracy 0.93421
Validation accuracy: 0.809474
Variance:0.00108199
loss:0.332065

step 800, training accuracy 0.960526
Validation accuracy: 0.823947
Variance:0.00134273
loss:0.111593

step 900, training accuracy 0.960526
Validation accuracy: 0.822105
Variance:0.00142133
loss:0.139094

step 1000, training accuracy 0.986842
Validation accuracy: 0.827632
Variance:0.00106129
loss:0.046909

step 1100, training accuracy 1
Validation accuracy: 0.840789
Variance:0.00149758
loss:0.111489

step 1200, training accuracy 0.973684
Validation accuracy: 0.819474
Variance:0.00124681
loss:0.0604571

step 1300, training accuracy 0.973684
Validation accuracy: 0.868684
Variance:0.000910595
loss:0.0519221

step 1400, training accuracy 0.986842
Validation accuracy: 0.828158
Variance:0.00144328
loss:0.0881034

step 1500, training accuracy 0.973684
Validation accuracy: 0.852105
Variance:0.00100803
loss:0.144006

step 1600, training accuracy 1
Validation accuracy: 0.792632
Variance:0.000973407
loss:0.114344

step 1700, training accuracy 0.973684
Validation accuracy: 0.844737
Variance:0.00130886
loss:0.0800164

step 1800, training accuracy 0.986842
Validation accuracy: 0.823684
Variance:0.000803324
loss:0.0718526

step 1900, training accuracy 0.960526
Validation accuracy: 0.833158
Variance:0.00114571
loss:0.0675592

step 2000, training accuracy 0.986842
Validation accuracy: 0.845526
Variance:0.000988989
loss:0.0129648

step 2100, training accuracy 0.986842
Validation accuracy: 0.811053
Variance:0.00159806
loss:0.0727629

step 2200, training accuracy 1
Validation accuracy: 0.845263
Variance:0.00122964
loss:0.0160648

step 2300, training accuracy 0.986842
Validation accuracy: 0.836579
Variance:0.00110173
loss:0.0441377

step 2400, training accuracy 0.986842
Validation accuracy: 0.835789
Variance:0.00120665
loss:0.0608515

step 2500, training accuracy 0.986842
Validation accuracy: 0.814737
Variance:0.0012662
loss:0.0558969

step 2600, training accuracy 1
Validation accuracy: 0.834211
Variance:0.00122576
loss:0.0140883

step 2700, training accuracy 1
Validation accuracy: 0.841842
Variance:0.00101447
loss:0.0265706

step 2800, training accuracy 0.986842
Validation accuracy: 0.828421
Variance:0.00130166
loss:0.190179

step 2900, training accuracy 1
Validation accuracy: 0.845789
Variance:0.00114294
loss:0.0361555

step 3000, training accuracy 0.986842
Validation accuracy: 0.827368
Variance:0.00102244
loss:0.0302574

0
[ 0.78947368  0.          0.0877193   0.          0.05263158  0.01754386
  0.03508772  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.01754386  0.        ]
1
[ 0.          0.92098765  0.00493827  0.02962963  0.00740741  0.01234568
  0.          0.00987654  0.          0.          0.          0.
  0.00493827  0.          0.          0.00740741  0.          0.
  0.00246914]
2
[ 0.02222222  0.          0.86666667  0.04444444  0.          0.
  0.04444444  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.02222222  0.        ]
3
[ 0.02564103  0.01282051  0.01282051  0.8974359   0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.03846154  0.          0.          0.          0.01282051  0.        ]
4
[ 0.          0.          0.          0.          0.99186992  0.
  0.00813008  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.        ]
5
[ 0.          0.          0.          0.          0.          0.98305085
  0.          0.          0.          0.          0.          0.
  0.01694915  0.          0.          0.          0.          0.          0.        ]
6
[  0.00000000e+00   0.00000000e+00   9.20810313e-04   0.00000000e+00
   6.44567219e-03   1.84162063e-03   9.86187845e-01   0.00000000e+00
   0.00000000e+00   2.76243094e-03   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.84162063e-03   0.00000000e+00   0.00000000e+00]
7
[ 0.          0.00952381  0.          0.          0.          0.0031746   0.
  0.96825397  0.          0.          0.          0.          0.01904762
  0.          0.          0.          0.          0.          0.        ]
8
[ 0.          0.          0.          0.          0.          0.          0.
  0.          0.94871795  0.          0.          0.          0.05128205
  0.          0.          0.          0.          0.          0.        ]
9
[ 0.          0.          0.          0.          0.          0.
  0.12211221  0.          0.          0.87788779  0.          0.          0.
  0.          0.          0.          0.          0.          0.        ]
10
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  0.]
11
[ 0.02380952  0.          0.          0.          0.          0.01587302
  0.          0.          0.          0.          0.06349206  0.8015873
  0.07142857  0.01587302  0.00793651  0.          0.          0.          0.        ]
12
[ 0.          0.          0.          0.          0.          0.01944444
  0.          0.00277778  0.          0.          0.          0.01111111
  0.625       0.          0.00277778  0.00555556  0.33333333  0.          0.        ]
13
[ 0.          0.44444444  0.          0.          0.          0.          0.
  0.16666667  0.          0.          0.          0.16666667  0.
  0.22222222  0.          0.          0.          0.          0.        ]
14
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.]
15
[ 0.          0.          0.          0.          0.          0.          0.
  0.          0.11111111  0.          0.          0.          0.22222222
  0.          0.          0.52777778  0.13888889  0.          0.        ]
16
[ 0.          0.          0.          0.          0.          0.00453515
  0.02040816  0.          0.          0.          0.          0.
  0.04988662  0.          0.          0.00680272  0.91609977  0.
  0.00226757]
17
[ 0.          0.          0.08333333  0.125       0.          0.04166667
  0.          0.          0.          0.          0.          0.
  0.04166667  0.          0.          0.          0.          0.70833333
  0.        ]
18
[ 0.          0.          0.          0.          0.          0.          0.0273224
  0.01092896  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.96174863]
Model saved in file: /home/fractal/workspace/02_hoi/4Deep/classes19/save_dir

Process finished with exit code 0
