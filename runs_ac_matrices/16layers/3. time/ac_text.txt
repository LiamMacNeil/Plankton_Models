/usr/bin/python3.5 "/home/fractal/PycharmProjects/hologram_SVM/check past_sixteen.py"
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.683
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.46GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
WARNING:tensorflow:From /home/fractal/PycharmProjects/hologram_SVM/check past_sixteen.py:205: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
train # 0
shape(?, 19)
shape(?, 19)
Tensor("Mean_3:0", shape=(), dtype=float32)
WARNING:tensorflow:From /home/fractal/PycharmProjects/hologram_SVM/check past_sixteen.py:444: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
step 0, training accuracy 0.0657895
Validation accuracy: 0.0523684
Variance:8.64959e-05
loss:3.69853

/usr/lib/python3/dist-packages/matplotlib/backend_bases.py:2437: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented
  warnings.warn(str, mplDeprecation)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 7286 get requests, put_count=7247 evicted_count=1000 eviction_rate=0.137988 and unsatisfied allocation rate=0.156327
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
step 100, training accuracy 0.842105
Validation accuracy: 0.672368
Variance:0.00157375
loss:0.749406

step 200, training accuracy 0.947368
Validation accuracy: 0.765789
Variance:0.00192521
loss:0.348176

step 300, training accuracy 0.921053
Validation accuracy: 0.806842
Variance:0.00118726
loss:0.420982

step 400, training accuracy 0.947368
Validation accuracy: 0.815
Variance:0.0011732
loss:0.21222

step 500, training accuracy 0.947368
Validation accuracy: 0.80421
Variance:0.00141717
loss:0.275102

step 600, training accuracy 0.947368
Validation accuracy: 0.823947
Variance:0.00155741
loss:0.177137

step 700, training accuracy 0.960526
Validation accuracy: 0.769211
Variance:0.00151115
loss:0.238462

step 800, training accuracy 0.986842
Validation accuracy: 0.855
Variance:0.0012153
loss:0.162372

step 900, training accuracy 0.973684
Validation accuracy: 0.852632
Variance:0.00117036
loss:0.188745

step 1000, training accuracy 0.973684
Validation accuracy: 0.826579
Variance:0.00123054
loss:0.0940442

step 1100, training accuracy 0.947368
Validation accuracy: 0.824737
Variance:0.00130499
loss:0.194088

step 1200, training accuracy 0.986842
Validation accuracy: 0.858947
Variance:0.00117756
loss:0.030194

step 1300, training accuracy 0.986842
Validation accuracy: 0.843684
Variance:0.00108476
loss:0.0425076

step 1400, training accuracy 0.947368
Validation accuracy: 0.863684
Variance:0.00171579
loss:0.237066

step 1500, training accuracy 0.934211
Validation accuracy: 0.803947
Variance:0.00137985
loss:0.349742

step 1600, training accuracy 0.960526
Validation accuracy: 0.867368
Variance:0.0010723
loss:0.295334

step 1700, training accuracy 0.973684
Validation accuracy: 0.807632
Variance:0.0011419
loss:0.103077

step 1800, training accuracy 0.973684
Validation accuracy: 0.865
Variance:0.00106516
loss:0.117136

step 1900, training accuracy 0.973684
Validation accuracy: 0.825789
Variance:0.00154127
loss:0.0784382

step 2000, training accuracy 0.973684
Validation accuracy: 0.833684
Variance:0.00167424
loss:0.129501

step 2100, training accuracy 0.973684
Validation accuracy: 0.846316
Variance:0.00113878
loss:0.0621449

step 2200, training accuracy 0.986842
Validation accuracy: 0.857368
Variance:0.00140831
loss:0.0477402

step 2300, training accuracy 1
Validation accuracy: 0.873684
Variance:0.00166898
loss:0.0181817

step 2400, training accuracy 1
Validation accuracy: 0.849474
Variance:0.00121302
loss:0.0145664

step 2500, training accuracy 1
Validation accuracy: 0.845263
Variance:0.000959557
loss:0.00405955

step 2600, training accuracy 0.973684
Validation accuracy: 0.807105
Variance:0.00111918
loss:0.0781442

step 2700, training accuracy 0.973684
Validation accuracy: 0.848421
Variance:0.00100582
loss:0.121608

step 2800, training accuracy 0.986842
Validation accuracy: 0.827368
Variance:0.00146565
loss:0.0537741

step 2900, training accuracy 1
Validation accuracy: 0.863947
Variance:0.00138234
loss:0.0091298

step 3000, training accuracy 0.986842
Validation accuracy: 0.844737
Variance:0.00120499
loss:0.0395308

0
[ 0.78947368  0.          0.0877193   0.          0.0877193   0.
  0.03508772  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.        ]
1
[ 0.          0.97530864  0.00740741  0.00246914  0.          0.          0.
  0.00740741  0.          0.          0.          0.          0.          0.
  0.          0.00740741  0.          0.          0.        ]
2
[ 0.02222222  0.          0.91111111  0.          0.          0.
  0.02222222  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.04444444  0.        ]
3
[ 0.02564103  0.          0.05128205  0.92307692  0.          0.          0.
  0.          0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.        ]
4
[ 0.          0.          0.          0.01219512  0.98780488  0.          0.
  0.          0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.        ]
5
[ 0.          0.          0.          0.          0.          0.9039548   0.
  0.02259887  0.          0.          0.          0.          0.05649718
  0.          0.          0.          0.01694915  0.          0.        ]
6
[  0.00000000e+00   0.00000000e+00   9.20810313e-04   0.00000000e+00
   2.85451197e-02   0.00000000e+00   9.60405157e-01   0.00000000e+00
   0.00000000e+00   1.84162063e-03   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   8.28729282e-03]
7
[ 0.          0.02222222  0.0031746   0.0031746   0.          0.01269841
  0.          0.93968254  0.          0.          0.          0.          0.
  0.          0.          0.00952381  0.00952381  0.          0.        ]
8
[ 0.          0.          0.          0.          0.          0.          0.
  0.          0.94871795  0.          0.          0.          0.03589744
  0.          0.01538462  0.          0.          0.          0.        ]
9
[ 0.          0.          0.          0.          0.          0.
  0.06930693  0.          0.          0.92079208  0.          0.          0.
  0.          0.          0.          0.          0.          0.00990099]
10
[ 0.          0.00813008  0.          0.          0.          0.          0.
  0.          0.          0.          0.95121951  0.04065041  0.          0.
  0.          0.          0.          0.          0.        ]
11
[ 0.          0.00793651  0.          0.00793651  0.          0.          0.
  0.00793651  0.          0.          0.03174603  0.94444444  0.          0.
  0.          0.          0.          0.          0.        ]
12
[ 0.          0.          0.          0.          0.          0.00833333
  0.          0.          0.          0.          0.          0.00833333
  0.53611111  0.          0.025       0.01388889  0.40833333  0.          0.        ]
13
[ 0.          0.5         0.          0.          0.          0.          0.
  0.05555556  0.          0.          0.          0.          0.16666667
  0.27777778  0.          0.          0.          0.          0.        ]
14
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.]
15
[ 0.          0.          0.          0.          0.          0.          0.
  0.          0.08333333  0.          0.          0.          0.08333333
  0.          0.          0.77777778  0.05555556  0.          0.        ]
16
[ 0.          0.00226757  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.02947846
  0.          0.          0.01587302  0.9478458   0.          0.00453515]
17
[ 0.          0.          0.16666667  0.125       0.          0.          0.
  0.          0.          0.          0.          0.          0.16666667
  0.          0.          0.          0.          0.54166667  0.        ]
18
[ 0.          0.          0.          0.          0.01092896  0.
  0.00546448  0.00546448  0.          0.          0.          0.          0.
  0.          0.00546448  0.          0.          0.          0.9726776 ]
Model saved in file: /home/fractal/workspace/02_hoi/4Deep/classes19/save_dir

Process finished with exit code 0
