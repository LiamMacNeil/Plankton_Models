/usr/bin/python3.5 "/home/fractal/PycharmProjects/hologram_SVM/check past two.py"
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.683
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 6.01GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
WARNING:tensorflow:From /home/fractal/PycharmProjects/hologram_SVM/check past two.py:192: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
train # 0
train # 100
train # 200
train # 300
Tensor("Mean_3:0", shape=(), dtype=float32)
WARNING:tensorflow:From /home/fractal/PycharmProjects/hologram_SVM/check past two.py:397: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
step 0, training accuracy 0.0526316
Validation accuracy: 0.0492105
Variance:0.000428047
loss:4.8111

/usr/lib/python3/dist-packages/matplotlib/backend_bases.py:2437: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented
  warnings.warn(str, mplDeprecation)
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 2.43GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 2.73GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
step 100, training accuracy 0.776316
Validation accuracy: 0.560526
Variance:0.00174515
loss:1.1383

step 200, training accuracy 0.868421
Validation accuracy: 0.598421
Variance:0.00217618
loss:0.82056

step 300, training accuracy 0.907895
Validation accuracy: 0.656053
Variance:0.0018491
loss:0.692927

step 400, training accuracy 0.947368
Validation accuracy: 0.678158
Variance:0.00153885
loss:0.501865

step 500, training accuracy 0.934211
Validation accuracy: 0.688947
Variance:0.00191662
loss:0.513339

step 600, training accuracy 0.960526
Validation accuracy: 0.668947
Variance:0.00194848
loss:0.437951

step 700, training accuracy 0.973684
Validation accuracy: 0.636053
Variance:0.00190173
loss:0.356583

step 800, training accuracy 0.973684
Validation accuracy: 0.67421
Variance:0.0023169
loss:0.303583

step 900, training accuracy 0.973684
Validation accuracy: 0.683947
Variance:0.00224716
loss:0.216505

step 1000, training accuracy 1
Validation accuracy: 0.688421
Variance:0.00237839
loss:0.132027

step 1100, training accuracy 0.986842
Validation accuracy: 0.664474
Variance:0.00141447
loss:0.162424

step 1200, training accuracy 0.973684
Validation accuracy: 0.699211
Variance:0.00181447
loss:0.21176

step 1300, training accuracy 0.973684
Validation accuracy: 0.688421
Variance:0.00215679
loss:0.190909

step 1400, training accuracy 0.986842
Validation accuracy: 0.666053
Variance:0.00168206
loss:0.173824

step 1500, training accuracy 0.986842
Validation accuracy: 0.691053
Variance:0.00172604
loss:0.188707

step 1600, training accuracy 1
Validation accuracy: 0.702632
Variance:0.00210526
loss:0.105027

step 1700, training accuracy 0.973684
Validation accuracy: 0.686579
Variance:0.00132057
loss:0.199818

step 1800, training accuracy 0.986842
Validation accuracy: 0.687368
Variance:0.00230997
loss:0.219428

step 1900, training accuracy 0.973684
Validation accuracy: 0.714737
Variance:0.00179668
loss:0.152319

step 2000, training accuracy 0.986842
Validation accuracy: 0.675789
Variance:0.0020482
loss:0.135857

step 2100, training accuracy 0.986842
Validation accuracy: 0.705789
Variance:0.00181274
loss:0.127859

step 2200, training accuracy 0.986842
Validation accuracy: 0.686579
Variance:0.00224162
loss:0.16835

step 2300, training accuracy 0.986842
Validation accuracy: 0.679474
Variance:0.00109945
loss:0.042177

step 2400, training accuracy 0.986842
Validation accuracy: 0.697632
Variance:0.00177625
loss:0.196235

step 2500, training accuracy 1
Validation accuracy: 0.683158
Variance:0.00261662
loss:0.163423

step 2600, training accuracy 1
Validation accuracy: 0.704474
Variance:0.00176046
loss:0.0972189

step 2700, training accuracy 1
Validation accuracy: 0.681579
Variance:0.00141967
loss:0.0483265

step 2800, training accuracy 0.986842
Validation accuracy: 0.694211
Variance:0.00155512
loss:0.152478

step 2900, training accuracy 1
Validation accuracy: 0.697632
Variance:0.00201863
loss:0.174708

step 3000, training accuracy 0.986842
Validation accuracy: 0.703684
Variance:0.00199612
loss:0.0640732

0
[ 0.59649123  0.0877193   0.07017544  0.05263158  0.05263158  0.
  0.10526316  0.          0.01754386  0.          0.          0.          0.
  0.          0.          0.          0.01754386  0.          0.        ]
1
[ 0.01728395  0.74320988  0.01728395  0.01975309  0.          0.0345679
  0.01481481  0.03950617  0.00493827  0.          0.00740741  0.04444444
  0.04197531  0.00246914  0.00740741  0.          0.          0.
  0.00493827]
2
[ 0.          0.          0.93333333  0.          0.02222222  0.
  0.04444444  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.        ]
3
[ 0.03846154  0.          0.1025641   0.58974359  0.          0.          0.
  0.01282051  0.          0.          0.03846154  0.03846154  0.02564103
  0.15384615  0.          0.          0.          0.          0.        ]
4
[ 0.00406504  0.          0.          0.          0.75203252  0.
  0.24390244  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.        ]
5
[ 0.          0.01694915  0.          0.          0.          0.84180791
  0.02824859  0.02259887  0.          0.00564972  0.          0.
  0.07344633  0.          0.          0.          0.01129944  0.          0.        ]
6
[  9.20810313e-04   0.00000000e+00   0.00000000e+00   0.00000000e+00
   6.44567219e-03   2.76243094e-03   9.85267035e-01   2.76243094e-03
   0.00000000e+00   1.84162063e-03   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00]
7
[ 0.          0.00952381  0.0031746   0.          0.          0.03174603
  0.0031746   0.87301587  0.          0.          0.          0.00634921
  0.06031746  0.          0.00634921  0.          0.00634921  0.          0.        ]
8
[ 0.          0.          0.          0.          0.          0.          0.
  0.          0.86153846  0.          0.          0.01538462  0.10769231
  0.          0.          0.          0.01025641  0.          0.00512821]
9
[ 0.          0.          0.          0.          0.          0.
  0.15511551  0.          0.          0.84488449  0.          0.          0.
  0.          0.          0.          0.          0.          0.        ]
10
[ 0.          0.03252033  0.          0.00813008  0.          0.          0.
  0.          0.          0.          0.8699187   0.07317073  0.01626016
  0.          0.          0.          0.          0.          0.        ]
11
[ 0.          0.05555556  0.          0.0952381   0.          0.          0.
  0.02380952  0.01587302  0.          0.19047619  0.46825397  0.08730159
  0.02380952  0.03968254  0.          0.          0.          0.        ]
12
[ 0.          0.01111111  0.          0.          0.          0.05277778
  0.          0.          0.          0.          0.          0.01111111
  0.625       0.          0.00277778  0.01666667  0.28055556  0.          0.        ]
13
[ 0.          0.05555556  0.          0.05555556  0.          0.          0.
  0.          0.          0.          0.11111111  0.11111111  0.
  0.66666667  0.          0.          0.          0.          0.        ]
14
[ 0.          0.05555556  0.          0.          0.          0.
  0.02777778  0.          0.05555556  0.          0.          0.          0.25
  0.          0.61111111  0.          0.          0.          0.        ]
15
[ 0.          0.          0.          0.          0.          0.          0.
  0.          0.13888889  0.          0.          0.          0.13888889
  0.          0.          0.66666667  0.05555556  0.          0.        ]
16
[ 0.          0.          0.          0.          0.          0.02721088
  0.03401361  0.          0.00680272  0.          0.          0.
  0.04081633  0.          0.00453515  0.00907029  0.87301587  0.
  0.00453515]
17
[ 0.          0.          0.16666667  0.33333333  0.          0.          0.
  0.          0.          0.          0.          0.20833333  0.20833333
  0.          0.          0.04166667  0.          0.04166667  0.        ]
18
[ 0.          0.          0.          0.          0.          0.
  0.01639344  0.01639344  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.96721311]
Model saved in file: /home/fractal/workspace/02_hoi/4Deep/classes19/save_dir

Process finished with exit code 0
